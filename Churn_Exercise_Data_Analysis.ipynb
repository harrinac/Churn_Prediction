{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Churn Analysis Exercise Notebook 2 of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-Learn for Modeling\n",
    "import sklearn\n",
    "\n",
    "# Pickle for saving model files\n",
    "import pickle\n",
    "\n",
    "# Import Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import RandomForestClassifier and GradientBoostingClassifer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Naive Bayes (Gaussian) has been reported as performing well on this dataset\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Function for splitting training and test set\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Function for creating model pipelines\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# For standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Helper for cross-validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Classification metrics (added later)\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Min-Max scaler (for use with Gaussian Classifiers)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Box-Cox transformation\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "# Used for custom transformers\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "# Import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feature Importance Statistical test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** We have created feature variables that capture the sales data trends as inclining or declining. We have also create an RSI momentum variable along with mean, and aggregate sale figures. **\n",
    "\n",
    "** The challenges now are to check whether is there correlation of trend movement to churn event\n",
    "and to verify customer service hypotheses:**\n",
    "** 1. Sales decline leads to end of business and churn**\n",
    "** 2. Signififcant increases in sales lead to the client securing other financing options and churning.**\n",
    "\n",
    "**We will also try to fit a predictive classification model to this data and present ana analysis of model fit and accuracy. **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** In the first notebook we have seen that higher RSI or sales momentum values seem to be associated\n",
    "with higher rates of churn. Here we will do a chi-square test to check feature importance**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load analytical base table \n",
    "df = pd.read_csv('data/churn_analytical_base_table.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test can only use positive values so we must drop columns with negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"supplier_key\", \"3_month_sales_change\", \"6_month_sales_change\", \"12_month_sales_change\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"3_month_sales_performance\"] = df[\"3_month_sales_performance\"].astype(np.float64)\n",
    "df[\"6_month_sales_performance\"] = df[\"6_month_sales_performance\"].astype(np.float64)\n",
    "df[\"12_month_sales_performance\"] = df[\"12_month_sales_performance\"].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the necessary columns\n",
    "df[\"3_month_mean_sales\"] = df[\"3_month_mean_sales\"] / df[\"3_month_mean_sales\"].max()\n",
    "df[\"6_month_mean_sales\"] = df[\"6_month_mean_sales\"] / df[\"6_month_mean_sales\"].max()\n",
    "df[\"12_month_mean_sales\"] = df[\"12_month_mean_sales\"] / df[\"12_month_mean_sales\"].max()\n",
    "df[\"total_mean_sales\"] = df[\"total_mean_sales\"] / df[\"total_mean_sales\"].max()\n",
    "df[\"3_month_rsi\"] = df[\"3_month_rsi\"] / df[\"3_month_rsi\"].max()\n",
    "df[\"6_month_rsi\"] = df[\"6_month_rsi\"] / df[\"6_month_rsi\"].max()\n",
    "df[\"12_month_rsi\"] = df[\"12_month_rsi\"] / df[\"12_month_rsi\"].max()\n",
    "df[\"3_month_total_sales\"] = df[\"3_month_total_sales\"] / df[\"3_month_total_sales\"].max()\n",
    "df[\"6_month_total_sales\"] = df[\"6_month_total_sales\"] / df[\"6_month_total_sales\"].max()\n",
    "df[\"12_month_total_sales\"] = df[\"12_month_total_sales\"] / df[\"12_month_total_sales\"].max()\n",
    "df[\"total_sales\"] = df[\"total_sales\"] / df[\"total_sales\"].max()\n",
    "df[\"3_month_sales_performance\"] = df[\"3_month_sales_performance\"] / df[\"3_month_sales_performance\"].max()\n",
    "df[\"6_month_sales_performance\"] = df[\"6_month_sales_performance\"] / df[\"6_month_sales_performance\"].max()\n",
    "df[\"12_month_sales_performance\"] = df[\"12_month_sales_performance\"] / df[\"12_month_sales_performance\"].max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>...</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "      <th>259</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>267</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3_month_mean_sales</th>\n",
       "      <td>0.016082</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>0.236946</td>\n",
       "      <td>0.004753</td>\n",
       "      <td>0.039190</td>\n",
       "      <td>0.005645</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.062143</td>\n",
       "      <td>0.008083</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.008613</td>\n",
       "      <td>0.005026</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.009895</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>0.037183</td>\n",
       "      <td>0.004101</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.021655</td>\n",
       "      <td>0.011156</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>0.005645</td>\n",
       "      <td>0.028058</td>\n",
       "      <td>0.080377</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>0.013484</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.014110</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.438159</td>\n",
       "      <td>0.003674</td>\n",
       "      <td>0.017803</td>\n",
       "      <td>0.003789</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.006208</td>\n",
       "      <td>0.069118</td>\n",
       "      <td>0.008501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.003918</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.007632</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.031317</td>\n",
       "      <td>0.020041</td>\n",
       "      <td>0.183064</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.004778</td>\n",
       "      <td>0.028393</td>\n",
       "      <td>0.005285</td>\n",
       "      <td>0.006073</td>\n",
       "      <td>0.019806</td>\n",
       "      <td>0.007831</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.016672</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.047682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010218</td>\n",
       "      <td>0.033818</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.009031</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.036137</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.017356</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.111675</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.010822</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.006269</td>\n",
       "      <td>0.004965</td>\n",
       "      <td>0.005668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_month_mean_sales</th>\n",
       "      <td>0.022338</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.011648</td>\n",
       "      <td>0.216161</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.031641</td>\n",
       "      <td>0.005830</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.035277</td>\n",
       "      <td>0.007836</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.011425</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.007678</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.004204</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.036775</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.008742</td>\n",
       "      <td>0.015146</td>\n",
       "      <td>0.011845</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.005907</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.039430</td>\n",
       "      <td>0.069457</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.013161</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.012583</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.558505</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.025940</td>\n",
       "      <td>0.007637</td>\n",
       "      <td>0.003852</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.019939</td>\n",
       "      <td>0.083264</td>\n",
       "      <td>0.006449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.009818</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>0.004911</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.084307</td>\n",
       "      <td>0.019032</td>\n",
       "      <td>0.348679</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>0.026981</td>\n",
       "      <td>0.010831</td>\n",
       "      <td>0.007848</td>\n",
       "      <td>0.013486</td>\n",
       "      <td>0.009126</td>\n",
       "      <td>0.002210</td>\n",
       "      <td>0.014187</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>0.048641</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.010031</td>\n",
       "      <td>0.019175</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.011024</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.043124</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.018859</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.075040</td>\n",
       "      <td>0.005363</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.017381</td>\n",
       "      <td>0.003578</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.005655</td>\n",
       "      <td>0.006163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_month_mean_sales</th>\n",
       "      <td>0.021044</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.008353</td>\n",
       "      <td>0.208404</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>0.030278</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.018340</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.004371</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.011188</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.006932</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.006147</td>\n",
       "      <td>0.045803</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>0.013715</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.006203</td>\n",
       "      <td>0.043324</td>\n",
       "      <td>0.052355</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.008549</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.012433</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.423632</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.025728</td>\n",
       "      <td>0.013128</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.027532</td>\n",
       "      <td>0.087413</td>\n",
       "      <td>0.008697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.004583</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.013598</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.005218</td>\n",
       "      <td>0.007124</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.105021</td>\n",
       "      <td>0.020556</td>\n",
       "      <td>0.317322</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.005569</td>\n",
       "      <td>0.018573</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>0.007011</td>\n",
       "      <td>0.009978</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>0.011883</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.053149</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>0.009969</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.014175</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.003110</td>\n",
       "      <td>0.045423</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.016477</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.054157</td>\n",
       "      <td>0.006353</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.017728</td>\n",
       "      <td>0.004338</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>0.006463</td>\n",
       "      <td>0.004939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_mean_sales</th>\n",
       "      <td>0.021212</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.005098</td>\n",
       "      <td>0.178252</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.052890</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>0.013345</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.018401</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.042759</td>\n",
       "      <td>0.002875</td>\n",
       "      <td>0.031036</td>\n",
       "      <td>0.005730</td>\n",
       "      <td>0.016145</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>0.053883</td>\n",
       "      <td>0.036966</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.006940</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.010084</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.243030</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>0.014099</td>\n",
       "      <td>0.029266</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.027083</td>\n",
       "      <td>0.160758</td>\n",
       "      <td>0.008619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>0.008424</td>\n",
       "      <td>0.006245</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.004046</td>\n",
       "      <td>0.003248</td>\n",
       "      <td>0.005107</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.294742</td>\n",
       "      <td>0.033147</td>\n",
       "      <td>0.397086</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.016055</td>\n",
       "      <td>0.034546</td>\n",
       "      <td>0.017132</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.008529</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>0.015091</td>\n",
       "      <td>0.002673</td>\n",
       "      <td>0.047733</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.004655</td>\n",
       "      <td>0.007544</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>0.008449</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>0.026921</td>\n",
       "      <td>0.005718</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.008937</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0.042662</td>\n",
       "      <td>0.008839</td>\n",
       "      <td>0.003379</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.018665</td>\n",
       "      <td>0.011758</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.009678</td>\n",
       "      <td>0.003335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_month_rsi</th>\n",
       "      <td>0.594022</td>\n",
       "      <td>0.511993</td>\n",
       "      <td>0.609754</td>\n",
       "      <td>0.105946</td>\n",
       "      <td>0.528968</td>\n",
       "      <td>0.517682</td>\n",
       "      <td>0.303099</td>\n",
       "      <td>0.515274</td>\n",
       "      <td>0.307511</td>\n",
       "      <td>0.491775</td>\n",
       "      <td>0.620665</td>\n",
       "      <td>0.499507</td>\n",
       "      <td>0.516670</td>\n",
       "      <td>0.467653</td>\n",
       "      <td>0.406164</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.477585</td>\n",
       "      <td>0.530291</td>\n",
       "      <td>0.600974</td>\n",
       "      <td>0.551154</td>\n",
       "      <td>0.577520</td>\n",
       "      <td>0.338806</td>\n",
       "      <td>0.541703</td>\n",
       "      <td>0.547308</td>\n",
       "      <td>0.332102</td>\n",
       "      <td>0.546583</td>\n",
       "      <td>0.471276</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>0.564551</td>\n",
       "      <td>0.378066</td>\n",
       "      <td>0.509168</td>\n",
       "      <td>0.421106</td>\n",
       "      <td>0.433808</td>\n",
       "      <td>0.576698</td>\n",
       "      <td>0.435596</td>\n",
       "      <td>0.470260</td>\n",
       "      <td>0.533181</td>\n",
       "      <td>0.480612</td>\n",
       "      <td>0.343561</td>\n",
       "      <td>0.284489</td>\n",
       "      <td>0.463202</td>\n",
       "      <td>0.477774</td>\n",
       "      <td>0.762466</td>\n",
       "      <td>0.372034</td>\n",
       "      <td>0.469567</td>\n",
       "      <td>0.532884</td>\n",
       "      <td>0.392258</td>\n",
       "      <td>0.754000</td>\n",
       "      <td>0.530984</td>\n",
       "      <td>0.399978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564599</td>\n",
       "      <td>0.551353</td>\n",
       "      <td>0.631444</td>\n",
       "      <td>0.495281</td>\n",
       "      <td>0.402171</td>\n",
       "      <td>0.454346</td>\n",
       "      <td>0.526980</td>\n",
       "      <td>0.274141</td>\n",
       "      <td>0.551293</td>\n",
       "      <td>0.623037</td>\n",
       "      <td>0.555230</td>\n",
       "      <td>0.654093</td>\n",
       "      <td>0.325485</td>\n",
       "      <td>0.727027</td>\n",
       "      <td>0.652484</td>\n",
       "      <td>0.427566</td>\n",
       "      <td>0.319543</td>\n",
       "      <td>0.613722</td>\n",
       "      <td>0.524172</td>\n",
       "      <td>0.517406</td>\n",
       "      <td>0.369714</td>\n",
       "      <td>0.575031</td>\n",
       "      <td>0.583766</td>\n",
       "      <td>0.489608</td>\n",
       "      <td>0.348604</td>\n",
       "      <td>0.907040</td>\n",
       "      <td>0.373700</td>\n",
       "      <td>0.357645</td>\n",
       "      <td>0.365080</td>\n",
       "      <td>0.522828</td>\n",
       "      <td>0.736061</td>\n",
       "      <td>0.606394</td>\n",
       "      <td>0.459034</td>\n",
       "      <td>0.308782</td>\n",
       "      <td>0.474132</td>\n",
       "      <td>0.716924</td>\n",
       "      <td>0.667643</td>\n",
       "      <td>0.580392</td>\n",
       "      <td>0.534372</td>\n",
       "      <td>0.577962</td>\n",
       "      <td>0.549928</td>\n",
       "      <td>0.234331</td>\n",
       "      <td>0.312805</td>\n",
       "      <td>0.693111</td>\n",
       "      <td>0.745357</td>\n",
       "      <td>0.513576</td>\n",
       "      <td>0.773109</td>\n",
       "      <td>0.203898</td>\n",
       "      <td>0.549350</td>\n",
       "      <td>0.524199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_month_rsi</th>\n",
       "      <td>0.653531</td>\n",
       "      <td>0.654602</td>\n",
       "      <td>0.714675</td>\n",
       "      <td>0.253678</td>\n",
       "      <td>0.568983</td>\n",
       "      <td>0.616118</td>\n",
       "      <td>0.439950</td>\n",
       "      <td>0.634212</td>\n",
       "      <td>0.366542</td>\n",
       "      <td>0.538051</td>\n",
       "      <td>0.598999</td>\n",
       "      <td>0.635695</td>\n",
       "      <td>0.534988</td>\n",
       "      <td>0.507404</td>\n",
       "      <td>0.461891</td>\n",
       "      <td>0.622902</td>\n",
       "      <td>0.512243</td>\n",
       "      <td>0.567634</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.661705</td>\n",
       "      <td>0.624996</td>\n",
       "      <td>0.488710</td>\n",
       "      <td>0.537788</td>\n",
       "      <td>0.553373</td>\n",
       "      <td>0.616855</td>\n",
       "      <td>0.577480</td>\n",
       "      <td>0.557114</td>\n",
       "      <td>0.625220</td>\n",
       "      <td>0.585646</td>\n",
       "      <td>0.533797</td>\n",
       "      <td>0.642454</td>\n",
       "      <td>0.481649</td>\n",
       "      <td>0.517111</td>\n",
       "      <td>0.650022</td>\n",
       "      <td>0.577724</td>\n",
       "      <td>0.543980</td>\n",
       "      <td>0.675239</td>\n",
       "      <td>0.559104</td>\n",
       "      <td>0.406070</td>\n",
       "      <td>0.585057</td>\n",
       "      <td>0.563565</td>\n",
       "      <td>0.610155</td>\n",
       "      <td>0.854760</td>\n",
       "      <td>0.509634</td>\n",
       "      <td>0.544517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.504289</td>\n",
       "      <td>0.909771</td>\n",
       "      <td>0.603618</td>\n",
       "      <td>0.500751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822278</td>\n",
       "      <td>0.709250</td>\n",
       "      <td>0.667209</td>\n",
       "      <td>0.605639</td>\n",
       "      <td>0.481101</td>\n",
       "      <td>0.514186</td>\n",
       "      <td>0.582912</td>\n",
       "      <td>0.366489</td>\n",
       "      <td>0.630285</td>\n",
       "      <td>0.753586</td>\n",
       "      <td>0.647952</td>\n",
       "      <td>0.714453</td>\n",
       "      <td>0.383955</td>\n",
       "      <td>0.720860</td>\n",
       "      <td>0.701862</td>\n",
       "      <td>0.561620</td>\n",
       "      <td>0.472964</td>\n",
       "      <td>0.742704</td>\n",
       "      <td>0.626954</td>\n",
       "      <td>0.584687</td>\n",
       "      <td>0.534602</td>\n",
       "      <td>0.642514</td>\n",
       "      <td>0.629009</td>\n",
       "      <td>0.570282</td>\n",
       "      <td>0.401253</td>\n",
       "      <td>0.640268</td>\n",
       "      <td>0.460335</td>\n",
       "      <td>0.420629</td>\n",
       "      <td>0.453607</td>\n",
       "      <td>0.630578</td>\n",
       "      <td>0.748104</td>\n",
       "      <td>0.673535</td>\n",
       "      <td>0.691510</td>\n",
       "      <td>0.377601</td>\n",
       "      <td>0.579676</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.621775</td>\n",
       "      <td>0.603741</td>\n",
       "      <td>0.732268</td>\n",
       "      <td>0.628648</td>\n",
       "      <td>0.647448</td>\n",
       "      <td>0.279820</td>\n",
       "      <td>0.529351</td>\n",
       "      <td>0.743731</td>\n",
       "      <td>0.641835</td>\n",
       "      <td>0.672994</td>\n",
       "      <td>0.643307</td>\n",
       "      <td>0.302138</td>\n",
       "      <td>0.567849</td>\n",
       "      <td>0.614247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_month_rsi</th>\n",
       "      <td>0.712275</td>\n",
       "      <td>0.790825</td>\n",
       "      <td>0.714783</td>\n",
       "      <td>0.355020</td>\n",
       "      <td>0.694366</td>\n",
       "      <td>0.726375</td>\n",
       "      <td>0.564410</td>\n",
       "      <td>0.892513</td>\n",
       "      <td>0.437429</td>\n",
       "      <td>0.624098</td>\n",
       "      <td>0.714352</td>\n",
       "      <td>0.713669</td>\n",
       "      <td>0.613585</td>\n",
       "      <td>0.603384</td>\n",
       "      <td>0.550273</td>\n",
       "      <td>0.693429</td>\n",
       "      <td>0.654835</td>\n",
       "      <td>0.735368</td>\n",
       "      <td>0.636135</td>\n",
       "      <td>0.749747</td>\n",
       "      <td>0.714353</td>\n",
       "      <td>0.735654</td>\n",
       "      <td>0.775468</td>\n",
       "      <td>0.672394</td>\n",
       "      <td>0.786205</td>\n",
       "      <td>0.687575</td>\n",
       "      <td>0.686560</td>\n",
       "      <td>0.721480</td>\n",
       "      <td>0.688449</td>\n",
       "      <td>0.687595</td>\n",
       "      <td>0.754278</td>\n",
       "      <td>0.594810</td>\n",
       "      <td>0.615670</td>\n",
       "      <td>0.723634</td>\n",
       "      <td>0.713643</td>\n",
       "      <td>0.599463</td>\n",
       "      <td>0.767959</td>\n",
       "      <td>0.698173</td>\n",
       "      <td>0.491156</td>\n",
       "      <td>0.495014</td>\n",
       "      <td>0.720921</td>\n",
       "      <td>0.682944</td>\n",
       "      <td>0.758338</td>\n",
       "      <td>0.680617</td>\n",
       "      <td>0.649311</td>\n",
       "      <td>0.910067</td>\n",
       "      <td>0.586257</td>\n",
       "      <td>0.768887</td>\n",
       "      <td>0.729526</td>\n",
       "      <td>0.797135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.804258</td>\n",
       "      <td>0.817920</td>\n",
       "      <td>0.772233</td>\n",
       "      <td>0.674210</td>\n",
       "      <td>0.567700</td>\n",
       "      <td>0.643963</td>\n",
       "      <td>0.733663</td>\n",
       "      <td>0.638477</td>\n",
       "      <td>0.745227</td>\n",
       "      <td>0.730897</td>\n",
       "      <td>0.665706</td>\n",
       "      <td>0.816910</td>\n",
       "      <td>0.626428</td>\n",
       "      <td>0.656727</td>\n",
       "      <td>0.783452</td>\n",
       "      <td>0.711216</td>\n",
       "      <td>0.544308</td>\n",
       "      <td>0.840336</td>\n",
       "      <td>0.765900</td>\n",
       "      <td>0.697675</td>\n",
       "      <td>0.686029</td>\n",
       "      <td>0.841958</td>\n",
       "      <td>0.740402</td>\n",
       "      <td>0.683404</td>\n",
       "      <td>0.609232</td>\n",
       "      <td>0.714359</td>\n",
       "      <td>0.535827</td>\n",
       "      <td>0.501961</td>\n",
       "      <td>0.540116</td>\n",
       "      <td>0.730816</td>\n",
       "      <td>0.775978</td>\n",
       "      <td>0.885348</td>\n",
       "      <td>0.682017</td>\n",
       "      <td>0.452653</td>\n",
       "      <td>0.690691</td>\n",
       "      <td>0.741773</td>\n",
       "      <td>0.704597</td>\n",
       "      <td>0.695478</td>\n",
       "      <td>0.833053</td>\n",
       "      <td>0.696926</td>\n",
       "      <td>0.750677</td>\n",
       "      <td>0.534872</td>\n",
       "      <td>0.765521</td>\n",
       "      <td>0.760446</td>\n",
       "      <td>0.741530</td>\n",
       "      <td>0.703349</td>\n",
       "      <td>0.811147</td>\n",
       "      <td>0.473429</td>\n",
       "      <td>0.722658</td>\n",
       "      <td>0.726659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_month_total_sales</th>\n",
       "      <td>0.016082</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>0.236946</td>\n",
       "      <td>0.004753</td>\n",
       "      <td>0.039190</td>\n",
       "      <td>0.005645</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.062143</td>\n",
       "      <td>0.008083</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.008613</td>\n",
       "      <td>0.005026</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.009895</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>0.037183</td>\n",
       "      <td>0.004101</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.021655</td>\n",
       "      <td>0.011156</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>0.005645</td>\n",
       "      <td>0.028058</td>\n",
       "      <td>0.080377</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>0.013484</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.014110</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.438159</td>\n",
       "      <td>0.003674</td>\n",
       "      <td>0.017803</td>\n",
       "      <td>0.003789</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.006208</td>\n",
       "      <td>0.069118</td>\n",
       "      <td>0.008501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.003918</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.007632</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.031317</td>\n",
       "      <td>0.020041</td>\n",
       "      <td>0.183064</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.004778</td>\n",
       "      <td>0.028393</td>\n",
       "      <td>0.005285</td>\n",
       "      <td>0.006073</td>\n",
       "      <td>0.019806</td>\n",
       "      <td>0.007831</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.016672</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.047682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010218</td>\n",
       "      <td>0.033818</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.009031</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.036137</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.017356</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.111675</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.010822</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.006269</td>\n",
       "      <td>0.004965</td>\n",
       "      <td>0.005668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_month_total_sales</th>\n",
       "      <td>0.022338</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.011648</td>\n",
       "      <td>0.216161</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.031641</td>\n",
       "      <td>0.005830</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.035277</td>\n",
       "      <td>0.007836</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.011425</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.007678</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.004204</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.036775</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.008742</td>\n",
       "      <td>0.015146</td>\n",
       "      <td>0.011845</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.005907</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.039430</td>\n",
       "      <td>0.069457</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>0.013161</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.012583</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.558505</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.025940</td>\n",
       "      <td>0.007637</td>\n",
       "      <td>0.003852</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.019939</td>\n",
       "      <td>0.083264</td>\n",
       "      <td>0.006449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.009818</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>0.004911</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.084307</td>\n",
       "      <td>0.019032</td>\n",
       "      <td>0.348679</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>0.026981</td>\n",
       "      <td>0.010831</td>\n",
       "      <td>0.007848</td>\n",
       "      <td>0.013486</td>\n",
       "      <td>0.009126</td>\n",
       "      <td>0.002210</td>\n",
       "      <td>0.014187</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>0.048641</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.010031</td>\n",
       "      <td>0.019175</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.011024</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.043124</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.018859</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.075040</td>\n",
       "      <td>0.005363</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.017381</td>\n",
       "      <td>0.003578</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.005655</td>\n",
       "      <td>0.006163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_month_total_sales</th>\n",
       "      <td>0.021044</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.008353</td>\n",
       "      <td>0.208404</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>0.030278</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.018340</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.004371</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.011188</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.006932</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.006147</td>\n",
       "      <td>0.045803</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>0.013715</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.006203</td>\n",
       "      <td>0.043324</td>\n",
       "      <td>0.052355</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.008549</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.012433</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.423632</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.025728</td>\n",
       "      <td>0.013128</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.027532</td>\n",
       "      <td>0.087413</td>\n",
       "      <td>0.008697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.004583</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.013598</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.005218</td>\n",
       "      <td>0.007124</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.105021</td>\n",
       "      <td>0.020556</td>\n",
       "      <td>0.317322</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.005569</td>\n",
       "      <td>0.018573</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>0.007011</td>\n",
       "      <td>0.009978</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>0.011883</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.053149</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>0.009969</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.014175</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.003110</td>\n",
       "      <td>0.045423</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.016477</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.054157</td>\n",
       "      <td>0.006353</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.017728</td>\n",
       "      <td>0.004338</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>0.006463</td>\n",
       "      <td>0.004939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_sales</th>\n",
       "      <td>0.015584</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.090945</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.028064</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.003237</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.018026</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>0.038396</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>0.020902</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.009885</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.002210</td>\n",
       "      <td>0.003586</td>\n",
       "      <td>0.052783</td>\n",
       "      <td>0.024895</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.006232</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.009878</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.163673</td>\n",
       "      <td>0.003501</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>0.022696</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.016582</td>\n",
       "      <td>0.085300</td>\n",
       "      <td>0.006508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.004298</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.010491</td>\n",
       "      <td>0.003303</td>\n",
       "      <td>0.002718</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.288727</td>\n",
       "      <td>0.017588</td>\n",
       "      <td>0.259321</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.005553</td>\n",
       "      <td>0.010485</td>\n",
       "      <td>0.021855</td>\n",
       "      <td>0.008741</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>0.007832</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>0.008316</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.024354</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.006207</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.021427</td>\n",
       "      <td>0.004901</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.006566</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>0.034826</td>\n",
       "      <td>0.008659</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.015618</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.001974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churned</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_month_sales_performance</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_month_sales_performance</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_month_sales_performance</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 284 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0         1         2         3         4    \\\n",
       "3_month_mean_sales          0.016082  0.000921  0.009926  0.236946  0.004753   \n",
       "6_month_mean_sales          0.022338  0.001413  0.011648  0.216161  0.003792   \n",
       "12_month_mean_sales         0.021044  0.001554  0.008353  0.208404  0.002491   \n",
       "total_mean_sales            0.021212  0.003945  0.005098  0.178252  0.001942   \n",
       "3_month_rsi                 0.594022  0.511993  0.609754  0.105946  0.528968   \n",
       "6_month_rsi                 0.653531  0.654602  0.714675  0.253678  0.568983   \n",
       "12_month_rsi                0.712275  0.790825  0.714783  0.355020  0.694366   \n",
       "3_month_total_sales         0.016082  0.000921  0.009926  0.236946  0.004753   \n",
       "6_month_total_sales         0.022338  0.001413  0.011648  0.216161  0.003792   \n",
       "12_month_total_sales        0.021044  0.001554  0.008353  0.208404  0.002491   \n",
       "total_sales                 0.015584  0.002335  0.003225  0.090945  0.001110   \n",
       "churned                     0.000000  0.000000  1.000000  1.000000  0.000000   \n",
       "3_month_sales_performance   0.200000  0.200000  0.400000  1.000000  1.000000   \n",
       "6_month_sales_performance   1.000000  0.200000  1.000000  1.000000  1.000000   \n",
       "12_month_sales_performance  1.000000  0.200000  0.600000  1.000000  1.000000   \n",
       "\n",
       "                                 5         6         7         8         9    \\\n",
       "3_month_mean_sales          0.039190  0.005645  0.000792  0.062143  0.008083   \n",
       "6_month_mean_sales          0.031641  0.005830  0.001176  0.035277  0.007836   \n",
       "12_month_mean_sales         0.030278  0.004635  0.002547  0.018340  0.004391   \n",
       "total_mean_sales            0.052890  0.002758  0.005469  0.013345  0.003323   \n",
       "3_month_rsi                 0.517682  0.303099  0.515274  0.307511  0.491775   \n",
       "6_month_rsi                 0.616118  0.439950  0.634212  0.366542  0.538051   \n",
       "12_month_rsi                0.726375  0.564410  0.892513  0.437429  0.624098   \n",
       "3_month_total_sales         0.039190  0.005645  0.000792  0.062143  0.008083   \n",
       "6_month_total_sales         0.031641  0.005830  0.001176  0.035277  0.007836   \n",
       "12_month_total_sales        0.030278  0.004635  0.002547  0.018340  0.004391   \n",
       "total_sales                 0.028064  0.001801  0.003237  0.007081  0.001696   \n",
       "churned                     1.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "3_month_sales_performance   1.000000  1.000000  0.200000  1.000000  1.000000   \n",
       "6_month_sales_performance   1.000000  1.000000  0.200000  0.600000  1.000000   \n",
       "12_month_sales_performance  0.200000  1.000000  0.200000  0.600000  0.600000   \n",
       "\n",
       "                                 10        11        12        13        14   \\\n",
       "3_month_mean_sales          0.001401  0.000866  0.008613  0.005026  0.002708   \n",
       "6_month_mean_sales          0.001165  0.000809  0.007825  0.003422  0.001752   \n",
       "12_month_mean_sales         0.000606  0.001087  0.004371  0.001779  0.000911   \n",
       "total_mean_sales            0.001125  0.001051  0.003063  0.001295  0.000663   \n",
       "3_month_rsi                 0.620665  0.499507  0.516670  0.467653  0.406164   \n",
       "6_month_rsi                 0.598999  0.635695  0.534988  0.507404  0.461891   \n",
       "12_month_rsi                0.714352  0.713669  0.613585  0.603384  0.550273   \n",
       "3_month_total_sales         0.001401  0.000866  0.008613  0.005026  0.002708   \n",
       "6_month_total_sales         0.001165  0.000809  0.007825  0.003422  0.001752   \n",
       "12_month_total_sales        0.000606  0.001087  0.004371  0.001779  0.000911   \n",
       "total_sales                 0.000551  0.000729  0.001688  0.000687  0.000352   \n",
       "churned                     1.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "3_month_sales_performance   1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "6_month_sales_performance   0.600000  0.200000  1.000000  0.600000  1.000000   \n",
       "12_month_sales_performance  0.200000  1.000000  0.600000  0.600000  0.600000   \n",
       "\n",
       "                                 15        16        17        18        19   \\\n",
       "3_month_mean_sales          0.009374  0.001073  0.009895  0.003817  0.000135   \n",
       "6_month_mean_sales          0.011425  0.001024  0.007678  0.004405  0.000260   \n",
       "12_month_mean_sales         0.011188  0.000638  0.006932  0.003673  0.000444   \n",
       "total_mean_sales            0.018401  0.000608  0.009497  0.002243  0.000603   \n",
       "3_month_rsi                 0.520833  0.477585  0.530291  0.600974  0.551154   \n",
       "6_month_rsi                 0.622902  0.512243  0.567634  0.651613  0.661705   \n",
       "12_month_rsi                0.693429  0.654835  0.735368  0.636135  0.749747   \n",
       "3_month_total_sales         0.009374  0.001073  0.009895  0.003817  0.000135   \n",
       "6_month_total_sales         0.011425  0.001024  0.007678  0.004405  0.000260   \n",
       "12_month_total_sales        0.011188  0.000638  0.006932  0.003673  0.000444   \n",
       "total_sales                 0.018026  0.000310  0.005233  0.001419  0.000492   \n",
       "churned                     0.000000  0.000000  1.000000  1.000000  1.000000   \n",
       "3_month_sales_performance   0.200000  1.000000  1.000000  0.600000  0.200000   \n",
       "6_month_sales_performance   1.000000  1.000000  1.000000  1.000000  0.200000   \n",
       "12_month_sales_performance  1.000000  1.000000  0.600000  1.000000  0.200000   \n",
       "\n",
       "                                 20        21        22        23        24   \\\n",
       "3_month_mean_sales          0.004012  0.003210  0.037183  0.004101  0.005332   \n",
       "6_month_mean_sales          0.004204  0.005025  0.036775  0.004004  0.008742   \n",
       "12_month_mean_sales         0.002185  0.006147  0.045803  0.002851  0.013715   \n",
       "total_mean_sales            0.001654  0.006642  0.042759  0.002875  0.031036   \n",
       "3_month_rsi                 0.577520  0.338806  0.541703  0.547308  0.332102   \n",
       "6_month_rsi                 0.624996  0.488710  0.537788  0.553373  0.616855   \n",
       "12_month_rsi                0.714353  0.735654  0.775468  0.672394  0.786205   \n",
       "3_month_total_sales         0.004012  0.003210  0.037183  0.004101  0.005332   \n",
       "6_month_total_sales         0.004204  0.005025  0.036775  0.004004  0.008742   \n",
       "12_month_total_sales        0.002185  0.006147  0.045803  0.002851  0.013715   \n",
       "total_sales                 0.000844  0.003931  0.038396  0.001526  0.020902   \n",
       "churned                     1.000000  0.000000  0.000000  1.000000  1.000000   \n",
       "3_month_sales_performance   1.000000  0.200000  1.000000  1.000000  0.200000   \n",
       "6_month_sales_performance   0.600000  0.200000  0.200000  1.000000  0.200000   \n",
       "12_month_sales_performance  0.600000  1.000000  0.600000  1.000000  0.200000   \n",
       "\n",
       "                                 25        26        27        28        29   \\\n",
       "3_month_mean_sales          0.021655  0.011156  0.000365  0.004578  0.005645   \n",
       "6_month_mean_sales          0.015146  0.011845  0.000594  0.005907  0.005935   \n",
       "12_month_mean_sales         0.007875  0.011456  0.000438  0.004775  0.006203   \n",
       "total_mean_sales            0.005730  0.016145  0.000344  0.003868  0.004881   \n",
       "3_month_rsi                 0.546583  0.471276  0.527407  0.564551  0.378066   \n",
       "6_month_rsi                 0.577480  0.557114  0.625220  0.585646  0.533797   \n",
       "12_month_rsi                0.687575  0.686560  0.721480  0.688449  0.687595   \n",
       "3_month_total_sales         0.021655  0.011156  0.000365  0.004578  0.005645   \n",
       "6_month_total_sales         0.015146  0.011845  0.000594  0.005907  0.005935   \n",
       "12_month_total_sales        0.007875  0.011456  0.000438  0.004775  0.006203   \n",
       "total_sales                 0.003041  0.009885  0.000176  0.002210  0.003586   \n",
       "churned                     1.000000  0.000000  1.000000  0.000000  0.000000   \n",
       "3_month_sales_performance   1.000000  1.000000  0.200000  0.200000  1.000000   \n",
       "6_month_sales_performance   1.000000  1.000000  1.000000  1.000000  0.600000   \n",
       "12_month_sales_performance  0.600000  0.800000  1.000000  1.000000  1.000000   \n",
       "\n",
       "                                 30        31        32        33        34   \\\n",
       "3_month_mean_sales          0.028058  0.080377  0.000872  0.000653  0.005092   \n",
       "6_month_mean_sales          0.039430  0.069457  0.000530  0.001083  0.003757   \n",
       "12_month_mean_sales         0.043324  0.052355  0.000276  0.001309  0.008549   \n",
       "total_mean_sales            0.053883  0.036966  0.000209  0.001415  0.006940   \n",
       "3_month_rsi                 0.509168  0.421106  0.433808  0.576698  0.435596   \n",
       "6_month_rsi                 0.642454  0.481649  0.517111  0.650022  0.577724   \n",
       "12_month_rsi                0.754278  0.594810  0.615670  0.723634  0.713643   \n",
       "3_month_total_sales         0.028058  0.080377  0.000872  0.000653  0.005092   \n",
       "6_month_total_sales         0.039430  0.069457  0.000530  0.001083  0.003757   \n",
       "12_month_total_sales        0.043324  0.052355  0.000276  0.001309  0.008549   \n",
       "total_sales                 0.052783  0.024895  0.000106  0.000866  0.006232   \n",
       "churned                     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3_month_sales_performance   0.200000  1.000000  1.000000  0.200000  1.000000   \n",
       "6_month_sales_performance   0.200000  1.000000  0.600000  0.200000  0.200000   \n",
       "12_month_sales_performance  0.200000  1.000000  0.600000  1.000000  1.000000   \n",
       "\n",
       "                                 35        36        37        38        39   \\\n",
       "3_month_mean_sales          0.013484  0.000118  0.014110  0.002321  0.438159   \n",
       "6_month_mean_sales          0.013161  0.000391  0.012583  0.001418  0.558505   \n",
       "12_month_mean_sales         0.008482  0.000423  0.012433  0.000783  0.423632   \n",
       "total_mean_sales            0.005733  0.000795  0.010084  0.000593  0.243030   \n",
       "3_month_rsi                 0.470260  0.533181  0.480612  0.343561  0.284489   \n",
       "6_month_rsi                 0.543980  0.675239  0.559104  0.406070  0.585057   \n",
       "12_month_rsi                0.599463  0.767959  0.698173  0.491156  0.495014   \n",
       "3_month_total_sales         0.013484  0.000118  0.014110  0.002321  0.438159   \n",
       "6_month_total_sales         0.013161  0.000391  0.012583  0.001418  0.558505   \n",
       "12_month_total_sales        0.008482  0.000423  0.012433  0.000783  0.423632   \n",
       "total_sales                 0.003276  0.000617  0.009878  0.000302  0.163673   \n",
       "churned                     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3_month_sales_performance   1.000000  0.200000  1.000000  1.000000  0.200000   \n",
       "6_month_sales_performance   1.000000  0.400000  1.000000  1.000000  1.000000   \n",
       "12_month_sales_performance  1.000000  0.200000  1.000000  0.600000  1.000000   \n",
       "\n",
       "                                 40        41        42        43        44   \\\n",
       "3_month_mean_sales          0.003674  0.017803  0.003789  0.003293  0.003012   \n",
       "6_month_mean_sales          0.004001  0.025940  0.007637  0.003852  0.001853   \n",
       "12_month_mean_sales         0.004202  0.025728  0.013128  0.003632  0.000964   \n",
       "total_mean_sales            0.003899  0.014099  0.029266  0.002446  0.000701   \n",
       "3_month_rsi                 0.463202  0.477774  0.762466  0.372034  0.469567   \n",
       "6_month_rsi                 0.563565  0.610155  0.854760  0.509634  0.544517   \n",
       "12_month_rsi                0.720921  0.682944  0.758338  0.680617  0.649311   \n",
       "3_month_total_sales         0.003674  0.017803  0.003789  0.003293  0.003012   \n",
       "6_month_total_sales         0.004001  0.025940  0.007637  0.003852  0.001853   \n",
       "12_month_total_sales        0.004202  0.025728  0.013128  0.003632  0.000964   \n",
       "total_sales                 0.003501  0.010359  0.022696  0.001847  0.000372   \n",
       "churned                     0.000000  0.000000  1.000000  0.000000  1.000000   \n",
       "3_month_sales_performance   0.800000  0.200000  0.200000  0.400000  1.000000   \n",
       "6_month_sales_performance   0.600000  1.000000  0.200000  1.000000  0.600000   \n",
       "12_month_sales_performance  1.000000  1.000000  0.200000  1.000000  0.600000   \n",
       "\n",
       "                                 45        46        47        48        49   \\\n",
       "3_month_mean_sales          0.000019  0.000928  0.006208  0.069118  0.008501   \n",
       "6_month_mean_sales          0.000219  0.001074  0.019939  0.083264  0.006449   \n",
       "12_month_mean_sales         0.001349  0.000566  0.027532  0.087413  0.008697   \n",
       "total_mean_sales            0.001788  0.000397  0.027083  0.160758  0.008619   \n",
       "3_month_rsi                 0.532884  0.392258  0.754000  0.530984  0.399978   \n",
       "6_month_rsi                 1.000000  0.504289  0.909771  0.603618  0.500751   \n",
       "12_month_rsi                0.910067  0.586257  0.768887  0.729526  0.797135   \n",
       "3_month_total_sales         0.000019  0.000928  0.006208  0.069118  0.008501   \n",
       "6_month_total_sales         0.000219  0.001074  0.019939  0.083264  0.006449   \n",
       "12_month_total_sales        0.001349  0.000566  0.027532  0.087413  0.008697   \n",
       "total_sales                 0.001168  0.000219  0.016582  0.085300  0.006508   \n",
       "churned                     1.000000  0.000000  1.000000  1.000000  0.000000   \n",
       "3_month_sales_performance   0.200000  0.600000  0.200000  0.200000  1.000000   \n",
       "6_month_sales_performance   0.200000  1.000000  0.200000  0.600000  0.200000   \n",
       "12_month_sales_performance  0.200000  0.600000  1.000000  0.200000  1.000000   \n",
       "\n",
       "                              ...          234       235       236       237  \\\n",
       "3_month_mean_sales            ...     0.000331  0.001266  0.000305  0.001040   \n",
       "6_month_mean_sales            ...     0.000781  0.002434  0.000842  0.001618   \n",
       "12_month_mean_sales           ...     0.001851  0.004583  0.001518  0.001034   \n",
       "total_mean_sales              ...     0.002338  0.008424  0.006245  0.000699   \n",
       "3_month_rsi                   ...     0.564599  0.551353  0.631444  0.495281   \n",
       "6_month_rsi                   ...     0.822278  0.709250  0.667209  0.605639   \n",
       "12_month_rsi                  ...     0.804258  0.817920  0.772233  0.674210   \n",
       "3_month_total_sales           ...     0.000331  0.001266  0.000305  0.001040   \n",
       "6_month_total_sales           ...     0.000781  0.002434  0.000842  0.001618   \n",
       "12_month_total_sales          ...     0.001851  0.004583  0.001518  0.001034   \n",
       "total_sales                   ...     0.002004  0.004298  0.005225  0.000399   \n",
       "churned                       ...     1.000000  1.000000  1.000000  1.000000   \n",
       "3_month_sales_performance     ...     0.200000  0.200000  0.200000  0.200000   \n",
       "6_month_sales_performance     ...     0.200000  0.200000  0.200000  1.000000   \n",
       "12_month_sales_performance    ...     0.200000  0.200000  0.200000  0.600000   \n",
       "\n",
       "                                 238       239       240       241       242  \\\n",
       "3_month_mean_sales          0.003918  0.001357  0.007632  0.002767  0.003433   \n",
       "6_month_mean_sales          0.003518  0.001022  0.009818  0.002505  0.004911   \n",
       "12_month_mean_sales         0.002332  0.000803  0.013598  0.002406  0.005218   \n",
       "total_mean_sales            0.001474  0.001591  0.013181  0.004046  0.003248   \n",
       "3_month_rsi                 0.402171  0.454346  0.526980  0.274141  0.551293   \n",
       "6_month_rsi                 0.481101  0.514186  0.582912  0.366489  0.630285   \n",
       "12_month_rsi                0.567700  0.643963  0.733663  0.638477  0.745227   \n",
       "3_month_total_sales         0.003918  0.001357  0.007632  0.002767  0.003433   \n",
       "6_month_total_sales         0.003518  0.001022  0.009818  0.002505  0.004911   \n",
       "12_month_total_sales        0.002332  0.000803  0.013598  0.002406  0.005218   \n",
       "total_sales                 0.000902  0.001396  0.010491  0.003303  0.002718   \n",
       "churned                     0.000000  0.000000  1.000000  0.000000  0.000000   \n",
       "3_month_sales_performance   1.000000  1.000000  0.200000  1.000000  0.200000   \n",
       "6_month_sales_performance   1.000000  1.000000  0.200000  1.000000  0.600000   \n",
       "12_month_sales_performance  1.000000  0.200000  1.000000  0.600000  1.000000   \n",
       "\n",
       "                                 243       244       245       246       247  \\\n",
       "3_month_mean_sales          0.002303  0.001142  0.031317  0.020041  0.183064   \n",
       "6_month_mean_sales          0.002752  0.001387  0.084307  0.019032  0.348679   \n",
       "12_month_mean_sales         0.007124  0.000880  0.105021  0.020556  0.317322   \n",
       "total_mean_sales            0.005107  0.000555  0.294742  0.033147  0.397086   \n",
       "3_month_rsi                 0.623037  0.555230  0.654093  0.325485  0.727027   \n",
       "6_month_rsi                 0.753586  0.647952  0.714453  0.383955  0.720860   \n",
       "12_month_rsi                0.730897  0.665706  0.816910  0.626428  0.656727   \n",
       "3_month_total_sales         0.002303  0.001142  0.031317  0.020041  0.183064   \n",
       "6_month_total_sales         0.002752  0.001387  0.084307  0.019032  0.348679   \n",
       "12_month_total_sales        0.007124  0.000880  0.105021  0.020556  0.317322   \n",
       "total_sales                 0.002814  0.000340  0.288727  0.017588  0.259321   \n",
       "churned                     1.000000  0.000000  0.000000  0.000000  1.000000   \n",
       "3_month_sales_performance   0.200000  0.200000  0.200000  1.000000  0.200000   \n",
       "6_month_sales_performance   0.200000  1.000000  0.200000  0.400000  1.000000   \n",
       "12_month_sales_performance  1.000000  0.600000  0.200000  0.400000  1.000000   \n",
       "\n",
       "                                 248       249       250       251       252  \\\n",
       "3_month_mean_sales          0.000228  0.004778  0.028393  0.005285  0.006073   \n",
       "6_month_mean_sales          0.000614  0.005675  0.026981  0.010831  0.007848   \n",
       "12_month_mean_sales         0.000986  0.005569  0.018573  0.013797  0.010686   \n",
       "total_mean_sales            0.003347  0.006803  0.016055  0.034546  0.017132   \n",
       "3_month_rsi                 0.652484  0.427566  0.319543  0.613722  0.524172   \n",
       "6_month_rsi                 0.701862  0.561620  0.472964  0.742704  0.626954   \n",
       "12_month_rsi                0.783452  0.711216  0.544308  0.840336  0.765900   \n",
       "3_month_total_sales         0.000228  0.004778  0.028393  0.005285  0.006073   \n",
       "6_month_total_sales         0.000614  0.005675  0.026981  0.010831  0.007848   \n",
       "12_month_total_sales        0.000986  0.005569  0.018573  0.013797  0.010686   \n",
       "total_sales                 0.002459  0.005553  0.010485  0.021855  0.008741   \n",
       "churned                     1.000000  0.000000  0.000000  1.000000  1.000000   \n",
       "3_month_sales_performance   0.200000  0.400000  1.000000  0.200000  0.200000   \n",
       "6_month_sales_performance   0.200000  1.000000  1.000000  0.200000  0.200000   \n",
       "12_month_sales_performance  0.200000  1.000000  1.000000  0.200000  0.600000   \n",
       "\n",
       "                                 253       254       255       256       257  \\\n",
       "3_month_mean_sales          0.019806  0.007831  0.000439  0.016672  0.002574   \n",
       "6_month_mean_sales          0.013486  0.009126  0.002210  0.014187  0.005164   \n",
       "12_month_mean_sales         0.007011  0.009978  0.003688  0.011883  0.003599   \n",
       "total_mean_sales            0.005102  0.008529  0.003443  0.015091  0.002673   \n",
       "3_month_rsi                 0.517406  0.369714  0.575031  0.583766  0.489608   \n",
       "6_month_rsi                 0.584687  0.534602  0.642514  0.629009  0.570282   \n",
       "12_month_rsi                0.697675  0.686029  0.841958  0.740402  0.683404   \n",
       "3_month_total_sales         0.019806  0.007831  0.000439  0.016672  0.002574   \n",
       "6_month_total_sales         0.013486  0.009126  0.002210  0.014187  0.005164   \n",
       "12_month_total_sales        0.007011  0.009978  0.003688  0.011883  0.003599   \n",
       "total_sales                 0.002707  0.007832  0.002178  0.008316  0.001964   \n",
       "churned                     1.000000  1.000000  1.000000  1.000000  0.000000   \n",
       "3_month_sales_performance   1.000000  0.400000  0.200000  1.000000  0.200000   \n",
       "6_month_sales_performance   0.600000  0.400000  0.200000  1.000000  1.000000   \n",
       "12_month_sales_performance  0.600000  1.000000  1.000000  1.000000  1.000000   \n",
       "\n",
       "                                 258       259       260       261       262  \\\n",
       "3_month_mean_sales          0.047682  0.000000  0.010218  0.033818  0.000773   \n",
       "6_month_mean_sales          0.048641  0.001099  0.010031  0.019175  0.000586   \n",
       "12_month_mean_sales         0.053149  0.000629  0.006350  0.009969  0.000315   \n",
       "total_mean_sales            0.047733  0.000425  0.004655  0.007544  0.000260   \n",
       "3_month_rsi                 0.348604  0.907040  0.373700  0.357645  0.365080   \n",
       "6_month_rsi                 0.401253  0.640268  0.460335  0.420629  0.453607   \n",
       "12_month_rsi                0.609232  0.714359  0.535827  0.501961  0.540116   \n",
       "3_month_total_sales         0.047682  0.000000  0.010218  0.033818  0.000773   \n",
       "6_month_total_sales         0.048641  0.001099  0.010031  0.019175  0.000586   \n",
       "12_month_total_sales        0.053149  0.000629  0.006350  0.009969  0.000315   \n",
       "total_sales                 0.024354  0.000243  0.002565  0.003849  0.000133   \n",
       "churned                     1.000000  1.000000  0.000000  0.000000  0.000000   \n",
       "3_month_sales_performance   1.000000  0.200000  1.000000  1.000000  1.000000   \n",
       "6_month_sales_performance   0.400000  1.000000  1.000000  0.600000  1.000000   \n",
       "12_month_sales_performance  1.000000  0.600000  1.000000  0.600000  1.000000   \n",
       "\n",
       "                                 263       264       265       266       267  \\\n",
       "3_month_mean_sales          0.001208  0.000123  0.009031  0.001205  0.004924   \n",
       "6_month_mean_sales          0.002395  0.001156  0.011024  0.001643  0.004739   \n",
       "12_month_mean_sales         0.002203  0.001342  0.014175  0.001218  0.003110   \n",
       "total_mean_sales            0.002389  0.007096  0.008449  0.000795  0.001804   \n",
       "3_month_rsi                 0.522828  0.736061  0.606394  0.459034  0.308782   \n",
       "6_month_rsi                 0.630578  0.748104  0.673535  0.691510  0.377601   \n",
       "12_month_rsi                0.730816  0.775978  0.885348  0.682017  0.452653   \n",
       "3_month_total_sales         0.001208  0.000123  0.009031  0.001205  0.004924   \n",
       "6_month_total_sales         0.002395  0.001156  0.011024  0.001643  0.004739   \n",
       "12_month_total_sales        0.002203  0.001342  0.014175  0.001218  0.003110   \n",
       "total_sales                 0.001560  0.004055  0.006207  0.000470  0.001215   \n",
       "churned                     0.000000  1.000000  0.000000  1.000000  0.000000   \n",
       "3_month_sales_performance   0.200000  0.200000  0.200000  0.200000  1.000000   \n",
       "6_month_sales_performance   1.000000  0.200000  0.200000  1.000000  1.000000   \n",
       "12_month_sales_performance  1.000000  0.200000  1.000000  0.600000  1.000000   \n",
       "\n",
       "                                 268       269       270       271       272  \\\n",
       "3_month_mean_sales          0.036137  0.001230  0.001032  0.001038  0.000235   \n",
       "6_month_mean_sales          0.043124  0.003001  0.001133  0.000909  0.000509   \n",
       "12_month_mean_sales         0.045423  0.002646  0.000786  0.000618  0.001729   \n",
       "total_mean_sales            0.026921  0.005718  0.001699  0.000450  0.001087   \n",
       "3_month_rsi                 0.474132  0.716924  0.667643  0.580392  0.534372   \n",
       "6_month_rsi                 0.579676  0.869048  0.621775  0.603741  0.732268   \n",
       "12_month_rsi                0.690691  0.741773  0.704597  0.695478  0.833053   \n",
       "3_month_total_sales         0.036137  0.001230  0.001032  0.001038  0.000235   \n",
       "6_month_total_sales         0.043124  0.003001  0.001133  0.000909  0.000509   \n",
       "12_month_total_sales        0.045423  0.002646  0.000786  0.000618  0.001729   \n",
       "total_sales                 0.021427  0.004901  0.000936  0.000239  0.000799   \n",
       "churned                     1.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3_month_sales_performance   0.400000  0.200000  0.800000  1.000000  0.200000   \n",
       "6_month_sales_performance   0.600000  1.000000  1.000000  1.000000  0.200000   \n",
       "12_month_sales_performance  1.000000  0.200000  0.200000  0.600000  1.000000   \n",
       "\n",
       "                                 273       274       275       276       277  \\\n",
       "3_month_mean_sales          0.017356  0.001761  0.111675  0.004372  0.002385   \n",
       "6_month_mean_sales          0.018859  0.002130  0.075040  0.005363  0.004443   \n",
       "12_month_mean_sales         0.016477  0.001942  0.054157  0.006353  0.004388   \n",
       "total_mean_sales            0.008937  0.002986  0.042662  0.008839  0.003379   \n",
       "3_month_rsi                 0.577962  0.549928  0.234331  0.312805  0.693111   \n",
       "6_month_rsi                 0.628648  0.647448  0.279820  0.529351  0.743731   \n",
       "12_month_rsi                0.696926  0.750677  0.534872  0.765521  0.760446   \n",
       "3_month_total_sales         0.017356  0.001761  0.111675  0.004372  0.002385   \n",
       "6_month_total_sales         0.018859  0.002130  0.075040  0.005363  0.004443   \n",
       "12_month_total_sales        0.016477  0.001942  0.054157  0.006353  0.004388   \n",
       "total_sales                 0.006566  0.002498  0.034826  0.008659  0.002000   \n",
       "churned                     0.000000  0.000000  0.000000  0.000000  1.000000   \n",
       "3_month_sales_performance   0.800000  0.200000  1.000000  0.200000  0.200000   \n",
       "6_month_sales_performance   1.000000  1.000000  1.000000  0.200000  1.000000   \n",
       "12_month_sales_performance  1.000000  0.200000  1.000000  0.600000  1.000000   \n",
       "\n",
       "                                 278       279       280       281       282  \\\n",
       "3_month_mean_sales          0.001127  0.010822  0.001257  0.006269  0.004965   \n",
       "6_month_mean_sales          0.001606  0.017381  0.003578  0.005162  0.005655   \n",
       "12_month_mean_sales         0.001276  0.017728  0.004338  0.004018  0.006463   \n",
       "total_mean_sales            0.000840  0.018665  0.011758  0.003691  0.009678   \n",
       "3_month_rsi                 0.745357  0.513576  0.773109  0.203898  0.549350   \n",
       "6_month_rsi                 0.641835  0.672994  0.643307  0.302138  0.567849   \n",
       "12_month_rsi                0.741530  0.703349  0.811147  0.473429  0.722658   \n",
       "3_month_total_sales         0.001127  0.010822  0.001257  0.006269  0.004965   \n",
       "6_month_total_sales         0.001606  0.017381  0.003578  0.005162  0.005655   \n",
       "12_month_total_sales        0.001276  0.017728  0.004338  0.004018  0.006463   \n",
       "total_sales                 0.000497  0.015618  0.006479  0.002561  0.005135   \n",
       "churned                     0.000000  0.000000  1.000000  0.000000  1.000000   \n",
       "3_month_sales_performance   0.200000  0.200000  0.200000  1.000000  0.600000   \n",
       "6_month_sales_performance   1.000000  0.600000  0.200000  1.000000  0.200000   \n",
       "12_month_sales_performance  1.000000  1.000000  0.200000  1.000000  0.600000   \n",
       "\n",
       "                                 283  \n",
       "3_month_mean_sales          0.005668  \n",
       "6_month_mean_sales          0.006163  \n",
       "12_month_mean_sales         0.004939  \n",
       "total_mean_sales            0.003335  \n",
       "3_month_rsi                 0.524199  \n",
       "6_month_rsi                 0.614247  \n",
       "12_month_rsi                0.726659  \n",
       "3_month_total_sales         0.005668  \n",
       "6_month_total_sales         0.006163  \n",
       "12_month_total_sales        0.004939  \n",
       "total_sales                 0.001974  \n",
       "churned                     1.000000  \n",
       "3_month_sales_performance   0.800000  \n",
       "6_month_sales_performance   1.000000  \n",
       "12_month_sales_performance  1.000000  \n",
       "\n",
       "[15 rows x 284 columns]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalized dataframe values\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = df.values\n",
    "#based on df dimensions nominate Y as target column number\n",
    "X = array[:,0:14]\n",
    "Y = array[:,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "test = SelectKBest(score_func=chi2, k=6)\n",
    "fit = test.fit(X, Y)\n",
    "# Summarize scores\n",
    "np.set_printoptions(precision=3)\n",
    "features = fit.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 5\n",
      "Selected Features: [False False False False False  True  True False False False False  True\n",
      "  True  True]\n",
      "Feature Ranking: [ 7  4  9 10  2  1  1  6  5  8  3  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 5)\n",
    "fit = rfe.fit(X, Y)\n",
    "print(\"Num Features: %s\" % (fit.n_features_))\n",
    "print(\"Selected Features: %s\" % (fit.support_))\n",
    "print(\"Feature Ranking: %s\" % (fit.ranking_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** The chi2 test is showing features 5,6,11,12,13 as most important. These are the 6 and 12 month RSI and the 3,6,12 month sales performance features.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Churn Prediction Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load analytical base table \n",
    "df = pd.read_csv('data/churn_analytical_base_table.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This is a classification task. We are trying to predict whether customers will churn or not. Here we follow a standard ML workflow. We split our data into train and tet sets and will parametrize and test the performance of 4 classification algorithms. The 4 algorithms used will be :\n",
    "\n",
    "    Regularized L1 logistic regression - penalize the absolute size of model coefficients.\n",
    "    Regularized L2 logistic regresion - penalize the squared size of model coefficients.\n",
    "    Random Forest Classifier\n",
    "    Gradient Boosting Classifier\n",
    "\n",
    "The model will give us a probability of whether a customer will churn or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate object for target variable\n",
    "y = df[\"churned\"]\n",
    "\n",
    "# Create separate object for input features\n",
    "X = df.drop([\"churned\", \"supplier_key\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** We will split the train/test set 80/20. We also stratify to ensure the target feature is balanced in each subset of data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227 57 227 57\n"
     ]
    }
   ],
   "source": [
    "# Split X and y into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=1234,\n",
    "                                                    stratify=df[\"churned\"])\n",
    "\n",
    "# Print number of observations in X_train, X_test, y_train, and y_test\n",
    "print( len(X_train), len(X_test), len(y_train), len(y_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44933920704845814"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In this sample c. 45% of the customers have churned.\n",
    "\n",
    "We will use 4 classification algorithms, create pipelines for each and set algorithm hyperparameters. Note that we standardize the feature values but subtracting means and dividing by standard deviation across the feature set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'l1' : make_pipeline(StandardScaler(), LogisticRegression(penalty='l1' , random_state=321)),\n",
    "    'l2' : make_pipeline(StandardScaler(), LogisticRegression(penalty='l2' , random_state=321)),\n",
    "    'rf' : make_pipeline(StandardScaler(), RandomForestClassifier(random_state=321)),\n",
    "    'gb' : make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=321))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression hyperparameters\n",
    "l1_hyperparameters = {'logisticregression__C' : np.linspace(1e-3, 1e3, 10),}\n",
    "l2_hyperparameters = {'logisticregression__C' : np.linspace(1e-3, 1e3, 10),}\n",
    "\n",
    "# Random Forest hyperparameters\n",
    "rf_hyperparameters = {\n",
    "    'randomforestclassifier__n_estimators': [20, 40],\n",
    "    'randomforestclassifier__max_features': ['auto', 'sqrt', 0.5],\n",
    "    'randomforestclassifier__min_samples_leaf': [1,3,5]\n",
    "}\n",
    "#Gradient Boosting hyperparameters\n",
    "gb_hyperparameters = {\n",
    "    'gradientboostingclassifier__n_estimators': [20, 40],\n",
    "    'gradientboostingclassifier__learning_rate': [0.05, 0.1, 0.2, 0.3],\n",
    "    'gradientboostingclassifier__max_depth': [1, 3, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'l1' : l1_hyperparameters,\n",
    "    'l2' : l2_hyperparameters,\n",
    "    'rf' : rf_hyperparameters,\n",
    "    'gb' : gb_hyperparameters\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use cross validation to tune each model. Here we use 10 fold cross-validation - i.e., we iteratively create 9 folds plus 1 hold-out fold and will average the training score over the 10 hold-out folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 has been fitted\n",
      "l2 has been fitted\n",
      "rf has been fitted\n",
      "gb has been fitted\n"
     ]
    }
   ],
   "source": [
    "fitted_models = {}\n",
    "#algs_to_test = ['l1', 'l2', 'rf', 'gb','gnb', 'bnb']\n",
    "algs_to_test = ['l1', 'l2','rf', 'gb']\n",
    "\n",
    "# Loop through model pipelines, tuning each one and saving it to fitted_models\n",
    "for name, pipeline in pipelines.items():\n",
    "    # Create cross-validation object from pipeline and hyperparameters\n",
    "    model = GridSearchCV(pipeline, hyperparameters[name], cv=5, n_jobs=-1)\n",
    "    \n",
    "    # Fit model on X_train, y_train\n",
    "    if name in algs_to_test:\n",
    "        model.fit(X_train, y_train)\n",
    "        fitted_models[name] = model\n",
    "        print(name, 'has been fitted')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the holdout accuracy scores. This is the percent of observations correctly classified by the models on the cross-validation training sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 0.6563876651982379\n",
      "l2 0.6563876651982379\n",
      "rf 0.6299559471365639\n",
      "gb 0.6387665198237885\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    print(name, model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3_month_rsi</th>\n",
       "      <td>0.126119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_month_rsi</th>\n",
       "      <td>0.121761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_mean_sales</th>\n",
       "      <td>0.078232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_month_mean_sales</th>\n",
       "      <td>0.071983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_month_sales_change</th>\n",
       "      <td>0.070945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_month_rsi</th>\n",
       "      <td>0.070011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_month_sales_change</th>\n",
       "      <td>0.065953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_month_mean_sales</th>\n",
       "      <td>0.060743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_sales</th>\n",
       "      <td>0.058000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_month_total_sales</th>\n",
       "      <td>0.057654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_month_total_sales</th>\n",
       "      <td>0.048382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_month_mean_sales</th>\n",
       "      <td>0.047025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_month_sales_change</th>\n",
       "      <td>0.040656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_month_total_sales</th>\n",
       "      <td>0.040250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_month_sales_performance</th>\n",
       "      <td>0.022116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_month_sales_performance</th>\n",
       "      <td>0.018451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_month_sales_performance</th>\n",
       "      <td>0.001721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            importance\n",
       "3_month_rsi                   0.126119\n",
       "12_month_rsi                  0.121761\n",
       "total_mean_sales              0.078232\n",
       "3_month_mean_sales            0.071983\n",
       "3_month_sales_change          0.070945\n",
       "6_month_rsi                   0.070011\n",
       "6_month_sales_change          0.065953\n",
       "6_month_mean_sales            0.060743\n",
       "total_sales                   0.058000\n",
       "3_month_total_sales           0.057654\n",
       "12_month_total_sales          0.048382\n",
       "12_month_mean_sales           0.047025\n",
       "12_month_sales_change         0.040656\n",
       "6_month_total_sales           0.040250\n",
       "3_month_sales_performance     0.022116\n",
       "6_month_sales_performance     0.018451\n",
       "12_month_sales_performance    0.001721"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the predicted probabilities from our fitted models on the test data\n",
    "pred_dict = {}\n",
    "\n",
    "if 'l1' in algs_to_test:\n",
    "    pred_l1 = fitted_models['l1'].predict(X_test)\n",
    "    prob_l1 = fitted_models['l1'].predict_proba(X_test)\n",
    "    pred_dict['pred_l1'] = pred_l1\n",
    "    pred_dict['prob_l1'] = prob_l1\n",
    "    \n",
    "    \n",
    "if 'l2' in algs_to_test:\n",
    "    pred_l2 = fitted_models['l2'].predict(X_test)\n",
    "    prob_l2 = fitted_models['l2'].predict_proba(X_test)\n",
    "    pred_dict['pred_l2'] = pred_l2\n",
    "    pred_dict['prob_l2'] = prob_l2\n",
    "    \n",
    "if 'rf' in algs_to_test:\n",
    "    pred_rf = fitted_models['rf'].predict(X_test)\n",
    "    prob_rf = fitted_models['rf'].predict_proba(X_test)\n",
    "    pred_dict['pred_rf'] = pred_rf\n",
    "    pred_dict['prob_rf'] = prob_rf\n",
    "    \n",
    "if 'gb' in algs_to_test:\n",
    "    pred_gb = fitted_models['gb'].predict(X_test)\n",
    "    prob_gb = fitted_models['gb'].predict_proba(X_test)\n",
    "    pred_dict['pred_gb'] = pred_gb\n",
    "    pred_dict['prob_gb'] = prob_gb\n",
    "    \n",
    "if 'gnb' in algs_to_test:\n",
    "    pred_gnb = fitted_models['gnb'].predict(X_test)\n",
    "    prob_gnb = fitted_models['gnb'].predict_proba(X_test)\n",
    "    pred_dict['pred_gnb'] =pred_gnb\n",
    "    pred_dict['prob_gnb'] = prob_gnb\n",
    "    \n",
    "if 'bnb' in algs_to_test:\n",
    "    pred_bnb = fitted_models['bnb'].predict(X_test)\n",
    "    prob_gnb = fitted_models['gnb'].predict_proba(X_test)\n",
    "    pred_dict['pred_bnb'] = pred_bnb\n",
    "    pred_dict['prob_bnb'] = prob_bnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Lets look at RandomForest Churn prediction performance in some more detail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, pred_dict['pred_rf'])\n",
    "plt.clf()\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Pastel2)\n",
    "classNames = ['Not Churned','Churned']\n",
    "plt.title('Not Churned versus Churned Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames, rotation=45)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives:  23 Correctly predicted \"Not Churned\" Customer\n",
      "False Positives:  9 Incorrectly predicted as \"Churned\"\n",
      "False Negatives:  9 Incorrectly predicted as \"Not Churned\"\n",
      "True Positives:  16 Correctly predicted as \"Churned\"\n"
     ]
    }
   ],
   "source": [
    "TN = cm[0,0]\n",
    "FP = cm[0,1]\n",
    "FN = cm[1,0]\n",
    "TP = cm[1,1]\n",
    "\n",
    "print(\"True Negatives: \", TN, \"Correctly predicted \\\"Not Churned\\\" Customer\")\n",
    "print(\"False Positives: \", FP, \"Incorrectly predicted as \\\"Churned\\\"\" )\n",
    "print(\"False Negatives: \", FN, \"Incorrectly predicted as \\\"Not Churned\\\"\")\n",
    "print(\"True Positives: \", TP, \"Correctly predicted as \\\"Churned\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorrect classification as a false positive or false negative has a specific name.\n",
    "    Type I Error: The incorrect rejection of a true null hypothesis or a false positive.\n",
    "    Type II Error: The incorrect failure of rejection of a false null hypothesis or a false negative.\n",
    "These value are plotted on the ROC curves below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.72      0.72        32\n",
      "          1       0.64      0.64      0.64        25\n",
      "\n",
      "avg / total       0.68      0.68      0.68        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_dict['pred_rf']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The sklearn documentation defines these values as follows: The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "\n",
    "The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "\n",
    "The F1 score can be interpreted as a weighted harmonic mean of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0.\n",
    "\n",
    "The support is the number of occurrences of each class in y_pred.\n",
    "\n",
    "The precision and recall scores are 0.68% respectively for predicting churn. This is \n",
    "an ok initial result, however the sample sizes are very small and therefore confidence is lower in these results. The last metric we will examine here is the ROC curve = Reciever Operating Characteristic plot. It is a way to visualize the relationship between TPR and FPR for classification models. It plots the true positive rate and false positive rate at different classification probability thresholds.\n",
    "\n",
    "As well as returning binary classifications of 0,1, for customer churned or not respectively, we can also look at the probability or confidence in each churn classiciation prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize plot\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.title('Receiver Operating Characteristic for GB and RF')\n",
    "\n",
    "# ---- L1 ---- #\n",
    "\n",
    "# Calculate ROC curve from y_test and the predicted probabilities for charged-off loans using the L1 algorithm.\n",
    "#The list comprehension below here returns the probabilities associated with charged-off predictions.\n",
    "fpr, tpr, thresholds = roc_curve(y_test, [p[1] for p in pred_dict['prob_l1']])\n",
    "\n",
    "# Calculates AUROC\n",
    "auroc = round(auc(fpr, tpr), 3)\n",
    "    \n",
    "# Plots ROC curve and labels with AUROC\n",
    "plt.plot(fpr, tpr, label='{} AUROC = {}'.format('L1', auroc))\n",
    "\n",
    "\n",
    "# ---- Gradient Boosting ---- #\n",
    "\n",
    "# Calculate ROC curve from y_test and the predicted probabilities for charged-off loans using the gb algorithm.\n",
    "#The list comprehension below here returns the probabilities associated with charged-off predictions.\n",
    "fpr, tpr, thresholds = roc_curve(y_test, [p[1] for p in pred_dict['prob_gb']])\n",
    "\n",
    "# Calculates AUROC\n",
    "auroc = round(auc(fpr, tpr), 3)\n",
    "    \n",
    "# Plots ROC curve and labels with AUROC\n",
    "plt.plot(fpr, tpr, label='{} AUROC = {}'.format('GB', auroc))\n",
    "\n",
    "\n",
    "# ---- Random Forest ---- #\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, [p[1] for p in pred_dict['prob_rf']])\n",
    "\n",
    "    \n",
    "# Calculates AUROC\n",
    "auroc = round(auc(fpr, tpr), 3)\n",
    "    \n",
    "# Plots ROC curve and labels with AUROC\n",
    "plt.plot(fpr, tpr, label='{} AUROC = {}'.format('RF', auroc))\n",
    "\n",
    "\n",
    "# ---- Legend and labels ---- #\n",
    "\n",
    "# Plot legend\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Plots 45 degree dotted black line\n",
    "plt.plot([0,1],[0,1],'k--', label='random guess')\n",
    "\n",
    "# Axes limits and labels\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The AUROC metric is robust against imbalanced classes and tells us the the likelihood that our model can distinguish between a randomly chosen customer that will churn versus a randomly chosen customer that will not churn.**\n",
    "\n",
    "** The RF algorithm perfomed best on the holdout data from the training set. When we test the batch of algorithms against the 20% of the test data we see that l1 Lasso regression algorithm performs well with a prediction accuracy of 0.78% of correctly predicting whether a customer will churn.**\n",
    "\n",
    "** Out of the box performance of 0.79 with a small dataset would encourage me to test this model on a much larger data set. The dataset is so small that it is difficult to say much about it with confidence.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Importance with Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Having fitted a random forest regressor, we can display the feature importance ranking as follows.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3_month_rsi</th>\n",
       "      <td>0.126119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_month_rsi</th>\n",
       "      <td>0.121761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_mean_sales</th>\n",
       "      <td>0.078232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_month_mean_sales</th>\n",
       "      <td>0.071983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_month_sales_change</th>\n",
       "      <td>0.070945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_month_rsi</th>\n",
       "      <td>0.070011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_month_sales_change</th>\n",
       "      <td>0.065953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_month_mean_sales</th>\n",
       "      <td>0.060743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_sales</th>\n",
       "      <td>0.058000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_month_total_sales</th>\n",
       "      <td>0.057654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_month_total_sales</th>\n",
       "      <td>0.048382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_month_mean_sales</th>\n",
       "      <td>0.047025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_month_sales_change</th>\n",
       "      <td>0.040656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_month_total_sales</th>\n",
       "      <td>0.040250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_month_sales_performance</th>\n",
       "      <td>0.022116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_month_sales_performance</th>\n",
       "      <td>0.018451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_month_sales_performance</th>\n",
       "      <td>0.001721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            importance\n",
       "3_month_rsi                   0.126119\n",
       "12_month_rsi                  0.121761\n",
       "total_mean_sales              0.078232\n",
       "3_month_mean_sales            0.071983\n",
       "3_month_sales_change          0.070945\n",
       "6_month_rsi                   0.070011\n",
       "6_month_sales_change          0.065953\n",
       "6_month_mean_sales            0.060743\n",
       "total_sales                   0.058000\n",
       "3_month_total_sales           0.057654\n",
       "12_month_total_sales          0.048382\n",
       "12_month_mean_sales           0.047025\n",
       "12_month_sales_change         0.040656\n",
       "6_month_total_sales           0.040250\n",
       "3_month_sales_performance     0.022116\n",
       "6_month_sales_performance     0.018451\n",
       "12_month_sales_performance    0.001721"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(fitted_models['l1'].best_estimator_.named_steps.logisticregression.coef_)\n",
    "#print(fitted_models['rf'].best_estimator_.named_steps.randomforestclassifier.feature_importances_)\n",
    "\n",
    "feature_importances = pd.DataFrame(fitted_models['rf'].best_estimator_.named_steps.randomforestclassifier.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance',ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** The RSI index for 3 and 12 months are rated highly by the RF.\n",
    "There is now some evidence that the RSI index is a useful predictor of churn.\n",
    "The evidence for the sales performance binned variables is weaker.\n",
    "A good next step would be to remodel this feature and test with more data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the best model for future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(fitted_models['l1'].best_estimator_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
